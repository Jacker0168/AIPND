{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1492, 2.6356, 2.4121],\n",
       "        [2.9150, 2.0636, 2.8838]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor\n",
    "x = torch.rand(3, 2)\n",
    "y = torch.ones(x.size())\n",
    "\n",
    "# index\n",
    "z = x + y\n",
    "z[0]\n",
    "z[:, 1:]\n",
    "\n",
    "# operation\n",
    "z.add(1)\n",
    "z.add_(1)\n",
    "z.resize_(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "# Define a transform to normalize the data\n",
    "# https://pytorch-cn.readthedocs.io/zh/latest/torchvision/torchvision-transform/\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(784, 400)),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(400, 200)),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('fc3', nn.Linear(200, 100)),\n",
    "                      ('relu3', nn.ReLU()),\n",
    "                      ('output', nn.Linear(100, 10)),\n",
    "                      ('softmax', nn.Softmax(dim = 1))]))\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "\n",
    "# another way\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. training neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 Loss: 1.9342 Test accuracy: 0.6054\n",
      "Epoch: 1/1 Loss: 1.1586 Test accuracy: 0.7762\n",
      "Epoch: 1/1 Loss: 0.7318 Test accuracy: 0.8087\n",
      "Epoch: 1/1 Loss: 0.6189 Test accuracy: 0.8108\n",
      "Epoch: 1/1 Loss: 0.5477 Test accuracy: 0.8632\n",
      "Epoch: 1/1 Loss: 0.4720 Test accuracy: 0.8588\n",
      "Epoch: 1/1 Loss: 0.4558 Test accuracy: 0.8778\n",
      "Epoch: 1/1 Loss: 0.4596 Test accuracy: 0.8862\n",
      "Epoch: 1/1 Loss: 0.4478 Test accuracy: 0.8863\n",
      "Epoch: 1/1 Loss: 0.4198 Test accuracy: 0.8868\n",
      "Epoch: 1/1 Loss: 0.4488 Test accuracy: 0.8863\n",
      "Epoch: 1/1 Loss: 0.4108 Test accuracy: 0.8874\n",
      "Epoch: 1/1 Loss: 0.3734 Test accuracy: 0.8842\n",
      "Epoch: 1/1 Loss: 0.3964 Test accuracy: 0.8847\n",
      "Epoch: 1/1 Loss: 0.3663 Test accuracy: 0.8970\n",
      "Epoch: 1/1 Loss: 0.3659 Test accuracy: 0.9071\n",
      "Epoch: 1/1 Loss: 0.3523 Test accuracy: 0.9052\n",
      "Epoch: 1/1 Loss: 0.3459 Test accuracy: 0.9063\n",
      "Epoch: 1/1 Loss: 0.3388 Test accuracy: 0.8997\n",
      "Epoch: 1/1 Loss: 0.3649 Test accuracy: 0.9064\n",
      "Epoch: 1/1 Loss: 0.3193 Test accuracy: 0.9091\n",
      "Epoch: 1/1 Loss: 0.2959 Test accuracy: 0.9161\n",
      "Epoch: 1/1 Loss: 0.2915 Test accuracy: 0.9164\n",
      "Epoch: 1/1 Loss: 0.3176 Test accuracy: 0.9110\n",
      "Epoch: 1/1 Loss: 0.2847 Test accuracy: 0.9117\n",
      "Epoch: 1/1 Loss: 0.3075 Test accuracy: 0.9097\n",
      "Epoch: 1/1 Loss: 0.2973 Test accuracy: 0.9161\n",
      "Epoch: 1/1 Loss: 0.3140 Test accuracy: 0.9166\n",
      "Epoch: 1/1 Loss: 0.3151 Test accuracy: 0.9180\n",
      "Epoch: 1/1 Loss: 0.2705 Test accuracy: 0.9194\n",
      "Epoch: 1/1 Loss: 0.2499 Test accuracy: 0.9223\n",
      "Epoch: 1/1 Loss: 0.2633 Test accuracy: 0.9250\n",
      "Epoch: 1/1 Loss: 0.2440 Test accuracy: 0.9196\n",
      "Epoch: 1/1 Loss: 0.2851 Test accuracy: 0.9209\n",
      "Epoch: 1/1 Loss: 0.2763 Test accuracy: 0.9207\n",
      "Epoch: 1/1 Loss: 0.2549 Test accuracy: 0.9158\n",
      "Epoch: 1/1 Loss: 0.2381 Test accuracy: 0.9195\n",
      "Epoch: 1/1 Loss: 0.2818 Test accuracy: 0.9301\n",
      "Epoch: 1/1 Loss: 0.2841 Test accuracy: 0.9306\n",
      "Epoch: 1/1 Loss: 0.2523 Test accuracy: 0.9283\n",
      "Epoch: 1/1 Loss: 0.2331 Test accuracy: 0.9340\n",
      "Epoch: 1/1 Loss: 0.2066 Test accuracy: 0.9288\n",
      "Epoch: 1/1 Loss: 0.2636 Test accuracy: 0.9172\n",
      "Epoch: 1/1 Loss: 0.2625 Test accuracy: 0.9312\n",
      "Epoch: 1/1 Loss: 0.2337 Test accuracy: 0.9336\n",
      "Epoch: 1/1 Loss: 0.2180 Test accuracy: 0.9378\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 200, 50, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        self.fc2 = nn.Linear(200, 50)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' This function for predicts classes by calculating the softmax '''\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits, dim=1)\n",
    "\n",
    "# # Hyperparameters for our network\n",
    "# input_size = 784\n",
    "# hidden_sizes = [128, 64]\n",
    "# output_size = 10\n",
    "\n",
    "# # Build a feed-forward network\n",
    "# net = nn.Sequential(OrderedDict([\n",
    "#                       ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "#                       ('relu1', nn.ReLU()),\n",
    "#                       ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "#                       ('relu2', nn.ReLU()),\n",
    "#                       ('logits', nn.Linear(hidden_sizes[1], output_size))]))\n",
    "    \n",
    "net = Network()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 20\n",
    "for e in range(epochs):\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        # Wrap images and labels in Variables so we can calculate gradients\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = net.forward(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # Test accuracy\n",
    "            accuracy = 0\n",
    "            for ii, (images, labels) in enumerate(testloader):\n",
    "                \n",
    "                images = images.resize_(images.size()[0], 784)\n",
    "                inputs = Variable(images)\n",
    "                \n",
    "                predicted = net.predict(inputs).data\n",
    "                equality = (labels == predicted.max(1)[1])\n",
    "                accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "            \n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every),\n",
    "                  \"Test accuracy: {:.4f}\".format(accuracy/(ii+1)))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get data\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# predict images\n",
    "img = images[1]\n",
    "ps = net.predict(Variable(img.resize_(1, 784)))\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fashion-MNIST Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 56.598..  Test Loss: 0.732..  Test Accuracy: 0.732\n",
      "Epoch: 1/2..  Training Loss: 57.417..  Test Loss: 0.634..  Test Accuracy: 0.763\n",
      "Epoch: 1/2..  Training Loss: 58.178..  Test Loss: 0.609..  Test Accuracy: 0.769\n",
      "Epoch: 1/2..  Training Loss: 58.860..  Test Loss: 0.606..  Test Accuracy: 0.771\n",
      "Epoch: 1/2..  Training Loss: 59.487..  Test Loss: 0.555..  Test Accuracy: 0.794\n",
      "Epoch: 1/2..  Training Loss: 60.098..  Test Loss: 0.586..  Test Accuracy: 0.779\n",
      "Epoch: 1/2..  Training Loss: 60.686..  Test Loss: 0.551..  Test Accuracy: 0.795\n",
      "Epoch: 1/2..  Training Loss: 61.289..  Test Loss: 0.515..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 61.902..  Test Loss: 0.520..  Test Accuracy: 0.813\n",
      "Epoch: 1/2..  Training Loss: 62.501..  Test Loss: 0.511..  Test Accuracy: 0.805\n",
      "Epoch: 1/2..  Training Loss: 63.055..  Test Loss: 0.497..  Test Accuracy: 0.821\n",
      "Epoch: 1/2..  Training Loss: 63.563..  Test Loss: 0.490..  Test Accuracy: 0.814\n",
      "Epoch: 1/2..  Training Loss: 64.129..  Test Loss: 0.512..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 64.691..  Test Loss: 0.487..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 65.244..  Test Loss: 0.478..  Test Accuracy: 0.824\n",
      "Epoch: 1/2..  Training Loss: 65.782..  Test Loss: 0.487..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 66.322..  Test Loss: 0.495..  Test Accuracy: 0.820\n",
      "Epoch: 1/2..  Training Loss: 66.840..  Test Loss: 0.472..  Test Accuracy: 0.826\n",
      "Epoch: 1/2..  Training Loss: 67.373..  Test Loss: 0.472..  Test Accuracy: 0.827\n",
      "Epoch: 1/2..  Training Loss: 67.928..  Test Loss: 0.460..  Test Accuracy: 0.832\n",
      "Epoch: 1/2..  Training Loss: 68.444..  Test Loss: 0.458..  Test Accuracy: 0.827\n",
      "Epoch: 1/2..  Training Loss: 68.987..  Test Loss: 0.484..  Test Accuracy: 0.823\n",
      "Epoch: 1/2..  Training Loss: 69.498..  Test Loss: 0.463..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 69.992..  Test Loss: 0.474..  Test Accuracy: 0.822\n",
      "Epoch: 2/2..  Training Loss: 70.518..  Test Loss: 0.461..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 71.042..  Test Loss: 0.455..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 71.568..  Test Loss: 0.459..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 72.073..  Test Loss: 0.455..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 72.568..  Test Loss: 0.442..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 73.042..  Test Loss: 0.453..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 73.526..  Test Loss: 0.457..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 74.019..  Test Loss: 0.441..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 74.490..  Test Loss: 0.436..  Test Accuracy: 0.843\n",
      "Epoch: 2/2..  Training Loss: 75.000..  Test Loss: 0.437..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 75.486..  Test Loss: 0.434..  Test Accuracy: 0.843\n",
      "Epoch: 2/2..  Training Loss: 75.940..  Test Loss: 0.462..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 76.389..  Test Loss: 0.434..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 76.863..  Test Loss: 0.434..  Test Accuracy: 0.843\n",
      "Epoch: 2/2..  Training Loss: 77.320..  Test Loss: 0.434..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 77.822..  Test Loss: 0.441..  Test Accuracy: 0.842\n",
      "Epoch: 2/2..  Training Loss: 78.295..  Test Loss: 0.442..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 78.753..  Test Loss: 0.444..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 79.272..  Test Loss: 0.428..  Test Accuracy: 0.845\n",
      "Epoch: 2/2..  Training Loss: 79.753..  Test Loss: 0.434..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 80.240..  Test Loss: 0.418..  Test Accuracy: 0.842\n",
      "Epoch: 2/2..  Training Loss: 80.729..  Test Loss: 0.447..  Test Accuracy: 0.837\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p = 0.5):\n",
    "        '''\n",
    "        input_size: len of vector\n",
    "        hidden_layer: [100, 200, 300]\n",
    "        output_size: classes\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # define neural network structure\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        # add drop out\n",
    "        self.dropout = nn.Dropout(p = drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        # Forward through each layer in `hidden_layers`, with ReLU activation and dropout\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# create the network, define the criterion and optimizer\n",
    "model = Network(784, 10, [516, 256], drop_p = 0.5)\n",
    "criterion = nn.NLLLoss()\n",
    "# Adam with momentum\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# training\n",
    "# period, gen\n",
    "epochs = 2\n",
    "steps = 0\n",
    "runnning_lose = 0\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    # dropout turn on when training\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if steps%print_every == 0:\n",
    "            # dropout turn off when inference\n",
    "            model.eval()   \n",
    "            accuracy = 0\n",
    "            test_loss = 0\n",
    "            \n",
    "#             # code as a function\n",
    "#             # Turn off gradients for validation, saves memory and computations\n",
    "#             with torch.no_grad():\n",
    "#                 test_loss, accuracy = validation(model, testloader, criterion)\n",
    "            \n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                for images, labels in testloader:\n",
    "                    images = images.resize_(images.size()[0], 784)\n",
    "                    output = model.forward(images)\n",
    "                    test_loss += criterion(output, labels).item()\n",
    "\n",
    "                    # calculate the accuracy\n",
    "                    ps = torch.exp(output).data\n",
    "                    equality = (labels.data == ps.max(dim=1)[1])\n",
    "                    # equality 0,1,0,1,1,1,0,0,0,0,1,1,1\n",
    "                    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            runnning_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test out your network!\n",
    "model.eval()\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "ps = torch.exp(output)\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=516, bias=True)\n",
      "    (1): Linear(in_features=516, out_features=256, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network(checkpoint['input_size'],\n",
    "                    checkpoint['output_size'],\n",
    "                    checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n",
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=516, bias=True)\n",
      "    (1): Linear(in_features=516, out_features=256, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n",
      "\n",
      "Original model\n",
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=516, bias=True)\n",
      "    (1): Linear(in_features=516, out_features=256, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              # the number of cell in the hidden layer\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              # the parameters trained in our network\n",
    "              'state_dict': model.state_dict()}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "model_load = load_checkpoint('checkpoint.pth')\n",
    "print('Loaded model')\n",
    "print(model_load)\n",
    "print()\n",
    "print('Original model')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cats and dogs problem & transfer learning\n",
    "* cannot run if no data\n",
    "* train on GPU\n",
    "* data source: https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whether we have GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "data_dir = '../Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "steps = 0\n",
    "\n",
    "# change to cuda\n",
    "model.to('cuda')\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "        print(loss.item)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* code with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above into functions, so they can be used later\n",
    "\n",
    "def do_deep_learning(model, trainloader, epochs, print_every, criterion, optimizer, device='cpu'):\n",
    "    epochs = epochs\n",
    "    print_every = print_every\n",
    "    steps = 0\n",
    "\n",
    "    # change to cuda\n",
    "    model.to('cuda')\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for ii, (inputs, labels) in enumerate(trainloader):\n",
    "            steps += 1\n",
    "\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward and backward passes\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                      \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "\n",
    "                running_loss = 0\n",
    "    \n",
    "def check_accuracy_on_test(testloader):    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    \n",
    "do_deep_learning(model, trainloader, 3, 40, criterion, optimizer, 'gpu')\n",
    "check_accuracy_on_test(testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
